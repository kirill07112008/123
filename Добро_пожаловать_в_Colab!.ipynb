{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirill07112008/123/blob/main/%D0%94%D0%BE%D0%B1%D1%80%D0%BE_%D0%BF%D0%BE%D0%B6%D0%B0%D0%BB%D0%BE%D0%B2%D0%B0%D1%82%D1%8C_%D0%B2_Colab!.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, features=[64, 128, 256, 512]):\n",
        "        super(UNet, self).__init__()\n",
        "        self.encoder = nn.ModuleList()\n",
        "        for feature in features:\n",
        "            self.encoder.append(self._conv_block(in_channels, feature))\n",
        "            in_channels = feature\n",
        "        self.bottleneck = self._conv_block(features[-1], features[-1] * 2)\n",
        "\n",
        "        self.decoder = nn.ModuleList()\n",
        "        # torch.Size([32, 64, 2]), torch.Size([32, 32, 4]), torch.Size([32, 16, 8]), torch.Size([32, 8, 16])\n",
        "        # [8, 16, 32, 64]\n",
        "        for feature in reversed(features):\n",
        "            self.decoder.append(nn.ConvTranspose1d(feature * 2, feature, kernel_size=2, stride=2))\n",
        "            self.decoder.append(self._conv_block(feature * 2, feature, div_by=1))\n",
        "\n",
        "        self.final_layer = nn.Conv1d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for layer in self.encoder:\n",
        "            x = layer(x)\n",
        "            skip_connections.append(x)\n",
        "            x = nn.MaxPool1d(kernel_size=2, stride=2)(x)\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        skip_connections = skip_connections[::-1]\n",
        "        # print(f\"Shapes: {[s.shape for s in skip_connections]}\")\n",
        "        # print(x.shape)\n",
        "        # print(self.decoder)\n",
        "        for idx in range(0, len(self.decoder), 2):\n",
        "            # print(f\"{self.decoder[idx]=}\")\n",
        "            # print(f\"{x.shape=}\")\n",
        "            x = self.decoder[idx](x)\n",
        "            skip_connection = skip_connections[idx // 2] # 1: 32, 8, 8\n",
        "            # print(skip_connection.shape, x.shape)\n",
        "\n",
        "            x = torch.cat((skip_connection, x), dim=1)\n",
        "            # print(f\"2: {x.shape=}\")\n",
        "            # print(f\"{self.decoder[idx + 1]=}\")\n",
        "            x = self.decoder[idx + 1](x)\n",
        "            # print(f\"{x.shape=}\")\n",
        "\n",
        "        return self.final_layer(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def _conv_block(in_channels, out_channels, div_by = 1):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(out_channels, out_channels // div_by, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "model = UNet(in_channels=1, out_channels=1, features=[1, 8, 16, 64])\n",
        "print(model)"
      ],
      "metadata": {
        "id": "Q7ro80mQUiom",
        "outputId": "bff42903-c969-4c03-b166-2ceb1099e134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet(\n",
            "  (encoder): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "      (2): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "      (2): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "      (2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (bottleneck): Sequential(\n",
            "    (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (1): ReLU()\n",
            "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (decoder): ModuleList(\n",
            "    (0): ConvTranspose1d(128, 64, kernel_size=(2,), stride=(2,))\n",
            "    (1): Sequential(\n",
            "      (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (2): ConvTranspose1d(32, 16, kernel_size=(2,), stride=(2,))\n",
            "    (3): Sequential(\n",
            "      (0): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "      (2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (4): ConvTranspose1d(16, 8, kernel_size=(2,), stride=(2,))\n",
            "    (5): Sequential(\n",
            "      (0): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "      (2): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (6): ConvTranspose1d(2, 1, kernel_size=(2,), stride=(2,))\n",
            "    (7): Sequential(\n",
            "      (0): Conv1d(2, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "      (2): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (final_layer): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'sessions.pickle'"
      ],
      "metadata": {
        "id": "0PGOxaekUzTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "VOCfmBdCU7s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"Файл {file_path} не найден\")\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "file_path = '/content/sessions.pickle'\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Файл {file_path} не найден. Проверьте путь.\")\n",
        "else:\n",
        "    clean_logs = load_dataset(file_path)\n",
        "    clean_logs = torch.Tensor(clean_logs['screen_seq']).view(100000, 16)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Используется устройство: {device}\")\n",
        "\n",
        "def linear_beta_schedule(timesteps):\n",
        "    beta_start = 1e-4\n",
        "    beta_end = 2e-2\n",
        "    return torch.linspace(beta_start, beta_end, timesteps)\n",
        "\n",
        "timesteps = 1000\n",
        "beta_schedule = linear_beta_schedule(timesteps)\n",
        "\n",
        "def forward_diffusion_process(x, t, noise_schedule):\n",
        "    beta_t = noise_schedule[t]\n",
        "    noise = torch.randn_like(x)\n",
        "    return torch.sqrt(1 - beta_t) * x + torch.sqrt(beta_t) * noise\n",
        "\n",
        "def reverse_diffusion_step(x, t, noise_schedule):\n",
        "    beta_t = noise_schedule[t]\n",
        "    noise = torch.randn_like(x)\n",
        "    sqrt_term = torch.sqrt(torch.clamp(1 - beta_t, min=1e-5))\n",
        "    return (x - torch.sqrt(beta_t) * noise) / sqrt_term\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "image = clean_logs\n",
        "noisy_image = forward_diffusion_process(image, 10, beta_schedule)\n",
        "denoised_image = reverse_diffusion_step(noisy_image, 10, beta_schedule)\n",
        "\n",
        "\n",
        "titles = [\"Изначальное\", \"Зашумленное\", \"После диффузии\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "predicted_noise = image\n",
        "actual_noise = denoised_image\n",
        "loss = loss_function(predicted_noise, actual_noise)\n",
        "\n",
        "print(f\"Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "AYRbpvuXU86G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []"
      ],
      "metadata": {
        "id": "IZeft-_UVGKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet(in_channels= 1 , out_channels= 1, features=[8, 16, 32, 64]).to(device)\n",
        "# print(model)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
        "\n",
        "epochs = 50\n",
        "timesteps = 1000\n",
        "beta_schedule = linear_beta_schedule(timesteps).to(device)\n",
        "batch_size = 32\n",
        "dataloader = DataLoader(clean_logs, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in  range(epochs):\n",
        "    print ( f\"Epoch {epoch+ 1 } / {epochs} \" )\n",
        "    for batch_idx, images in  enumerate (dataloader):\n",
        "        images = images.to(device)\n",
        "\n",
        "        t = torch.randint( 0 , timesteps, (images.size( 1 ),)).to(device)\n",
        "        noise_images = forward_diffusion_process(images, t, beta_schedule)\n",
        "        noise = torch.randn_like(images)\n",
        "        # print(t.shape, noise_images.shape)\n",
        "        predicted_noise = model(noise_images.unsqueeze(1))\n",
        "\n",
        "        loss = loss_function(predicted_noise, noise)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 10 == 0 :\n",
        "            print ( f\"Batch {batch_idx} / { len (dataloader)} - Loss: {loss.item(): .4f} \" )\n",
        "    losses.append(loss.item())"
      ],
      "metadata": {
        "id": "a_WyLSLGVG5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TeHZyVXOVRsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "id": "hbnc41uQVSUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_logs[200]"
      ],
      "metadata": {
        "id": "13w9aW7kVUon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_session = [544, 335, 10, 335, 335, 16, 335, 10, 402, 545, 547., 547., 547., 547., 547., 547.]\n",
        "# Шумная сессия"
      ],
      "metadata": {
        "id": "LgDR04LaVYJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_session = torch.Tensor(noisy_session).view(1, -1).unsqueeze(1).cuda()"
      ],
      "metadata": {
        "id": "oSXksNFVVa1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = model(noisy_session)"
      ],
      "metadata": {
        "id": "U7dy4howVdVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise\n",
        "#шум"
      ],
      "metadata": {
        "id": "bu8XttEmVf4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_session = noisy_session - noise"
      ],
      "metadata": {
        "id": "Hq9dSPNwVjHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_session\n",
        "# очищенная сессия"
      ],
      "metadata": {
        "id": "zPZwmupXVlhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "titles = [\"Зашумленное\", \"Шум\", \"После диффузии\"]\n",
        "\n",
        "for i, img in enumerate([noisy_session.cpu(), noise.cpu().detach(), clean_session.cpu().detach()]):\n",
        "    axes[i].imshow(img.permute(1, 2, 0).numpy())\n",
        "    axes[i].set_title(titles[i])\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "avKAEWUXVn0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_diffusion_process(x, t, noise_schedule):\n",
        "    beta_t = noise_schedule[t]\n",
        "    noise = torch.randn_like(x)\n",
        "    return torch.sqrt(1 - beta_t) * x + torch.sqrt(beta_t) * noise\n",
        "\n",
        "noise_slap = forward_diffusion_process(clean_logs[0],10, beta_schedule)\n",
        "print(noise_slap)"
      ],
      "metadata": {
        "id": "N9R8PZKFVqEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_logs = load_dataset(file_path)\n",
        "clean_logs = torch.Tensor(clean_logs['screen_seq']).view(100000, 16)"
      ],
      "metadata": {
        "id": "ixfHQUz6VtTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
        "titles = [\"Чистый лог\",\"Зашумленное\", \"Шум\", \"После диффузии\"]\n",
        "\n",
        "for i, img in enumerate([clean_logs[0].unsqueeze(0).unsqueeze(0).cpu(),clean_logs[0].unsqueeze(0).unsqueeze(0).cpu() + noise.cpu().detach(),noise.cpu().detach(), clean_session.cpu().detach()]):\n",
        "    axes[i].imshow(img.permute(1, 2, 0).numpy())\n",
        "    axes[i].set_title(titles[i])\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "print(clean_logs[0].unsqueeze(0).unsqueeze(0).cpu(),clean_logs[0].unsqueeze(0).unsqueeze(0).cpu() + noise.cpu().detach(),noise.cpu().detach(), clean_session.cpu().detach())\n",
        "\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "Gx6i3yCpVwDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_logs[0].view(1, -1).unsqueeze(1).shape"
      ],
      "metadata": {
        "id": "LirvKTVHVygY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_diffusion_step(x, t, noise_schedule):\n",
        "    beta_t = noise_schedule[t]\n",
        "    noise = torch.randn_like(x)\n",
        "    sqrt_term = torch.sqrt(torch.clamp(1 - beta_t, min=1e-5))\n",
        "    return (x - torch.sqrt(beta_t) * noise) / sqrt_term\n",
        "\n",
        "clean_session = forward_diffusion_process(noise_slap,10, beta_schedule)\n",
        "print(clean_session)"
      ],
      "metadata": {
        "id": "uGfPXNPJV1Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
        "titles = [\"Чистый лог\",\"Зашумленное\", \"Шум\", \"После диффузии\"]\n",
        "\n",
        "for i, img in enumerate([clean_logs[0].unsqueeze(0).unsqueeze(0).cpu(),clean_logs[0].unsqueeze(0).unsqueeze(0).cpu() + noise.cpu().detach(),noise.cpu().detach(), clean_session.cpu().unsqueeze(0).unsqueeze(0).detach()]):\n",
        "    axes[i].imshow(img.permute(1, 2, 0).numpy())\n",
        "    axes[i].set_title(titles[i])\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "print(clean_logs[0].unsqueeze(0).unsqueeze(0).cpu(),clean_logs[0].unsqueeze(0).unsqueeze(0).cpu() + noise.cpu().detach(),noise.cpu().detach(), clean_session.cpu().detach())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ec4hzJ5MV4_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
        "titles = [\"Чистый лог\",\"Зашумленное\", \"Шум\", \"После диффузии\"]\n",
        "\n",
        "for i, img in enumerate([clean_logs[0].unsqueeze(0).unsqueeze(0).cpu(),clean_logs[0].unsqueeze(0).unsqueeze(0).cpu() + noise.cpu().detach(),noise.cpu().detach(), clean_session.cpu().unsqueeze(0).unsqueeze(0).detach()]):\n",
        "    axes[i].imshow(img.permute(1, 2, 0).numpy())\n",
        "    axes[i].set_title(titles[i])\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "print(clean_logs[0].unsqueeze(0).unsqueeze(0).cpu(),clean_logs[0].unsqueeze(0).unsqueeze(0).cpu() + noise.cpu().detach(),noise.cpu().detach(), clean_session.cpu().detach())\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
        "titles = [\"Чистый лог\",\"Зашумленное\", \"Шум\", \"После диффузии\"]\n",
        "\n",
        "for i, img in enumerate([clean_logs[0].unsqueeze(0).unsqueeze(0).cpu(),clean_logs[0].unsqueeze(0).unsqueeze(0).cpu() + noise.cpu().detach(),noise.cpu().detach(), clean_session.cpu().detach()]):\n",
        "    axes[i].imshow(img.permute(1, 2, 0).numpy())\n",
        "    axes[i].set_title(titles[i])\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "print(clean_logs[0].unsqueeze(0).unsqueeze(0).cpu(),clean_logs[0].unsqueeze(0).unsqueeze(0).cpu() + noise.cpu().detach(),noise.cpu().detach(), clean_session.cpu().detach())\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print((clean_session.cpu().detach())-(clean_session.cpu().detach))"
      ],
      "metadata": {
        "id": "mZEQb6NXV7hp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Добро пожаловать в Colab!",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}